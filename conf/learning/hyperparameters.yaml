epochs: 1e4
optimizer: Adam
learning_rate: 1e-5
batch_size: 3

init_temperature: 1e-2 # initialization temp param for logits

num_states: 2 # in general, depends on the quantifer, so should be overridden