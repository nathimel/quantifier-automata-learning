epochs: 10
optimizer: Adam
learning_rate: 1e-5
batch_size: 8

init_temperature: 1e-2 # initialization temp param for logits

num_states: 2 # in general, depends on the quantifer, so should be overridden