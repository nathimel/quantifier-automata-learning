epochs: 1e4
optimizer: Adam
learning_rate: 1e-3
batch_size: 3

# Stopping criterions
patience: 100 # how many consecutive epochs with no change
loss_threshold: 0.01
accuracy_threshold: 0.99

init_temperature: 1e5 # initialization temp param for logits, larger -> more uniform

num_states: 2 # in general, depends on the quantifer, so should be overridden

threshold: 0.5 # greater than equal to this threshold for predicting True in  binary classification accuracy